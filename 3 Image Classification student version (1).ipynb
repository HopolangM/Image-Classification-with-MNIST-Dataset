{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "q4sO-peK5nPe"
   },
   "source": [
    "# Introduction to Image Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rio6wWWK5nPg"
   },
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jrCXrw5X5nPk"
   },
   "source": [
    "## Imports\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQbyemE45nPp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip # This is used in extracting the images\n",
    "\n",
    "import matplotlib.pyplot as plt # In order to plot the images to see what we are dealing with\n",
    "from sklearn.ensemble import RandomForestClassifier # You'll be using Random Forest to classify the images\n",
    "from sklearn.metrics import accuracy_score # Sklearn's way of measuring accuracy\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XG1aYu7_5nP1"
   },
   "source": [
    "## The Dataset\n",
    "The dataset we will be using is called MNIST. This is a large collection of handdrawn digits 0-9 and is a good dataset to learn image classification on as it requires little to no preprocessing.\n",
    "\n",
    "The dataset can be downloaded from [The MNIST Database](http://yann.lecun.com/exdb/mnist/). Download all four files. These files are the images and their respective labels and the dataset has already been split into a train and a test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-62g3Rdn5nP9"
   },
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY2_-9ai5nQF"
   },
   "source": [
    "## Question 1 - Extracting the data\n",
    "\n",
    "The MNIST dataset consists for 60 000 training images and 10 000 testing images. This is a lot of data! Let's not extract all of that right now. Create a function `get_data` that uses the above functions to extract a certain number of images and their labels from the gzip files.\n",
    "\n",
    "The function will take as input two integer values and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the extracted images / labels of the training set, and `(X-test, y_test)` are the extracted images / labels of the testing set.\n",
    "\n",
    "Image pixel values range from 0-255. Normalise the image pixels so that they are in the range 0-1.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two integers as input, one representing the number of training images, and the other the number of testing images.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "_**Note**_ that the size of the MNIST images are 28x28\n",
    "\n",
    "Usually when setting up your dataset, it is a good idea to randomly shuffle your data in case your data is ordered. Think of this as shuffling a pack of cards. Here, however, we aren't going to shuffle the data so that all our answers are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BpvzeRX5nQJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(1000,)\n",
      "(5000, 784)\n",
      "(1000, 784)\n",
      "0.10980392\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "### START FUNCTION\n",
    "import gzip\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "def get_data(num_train_images, num_test_images):\n",
    "    # Load training data\n",
    "    X_train = read_idx('train-images-idx3-ubyte.gz')\n",
    "    y_train = read_idx('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # Load testing data\n",
    "    X_test = read_idx('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = read_idx('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "    # Extract the specified number of images and labels\n",
    "    X_train = X_train[:num_train_images].reshape((num_train_images, 28 * 28))\n",
    "    y_train = y_train[:num_train_images]\n",
    "    X_test = X_test[:num_test_images].reshape((num_test_images, 28 * 28))\n",
    "    y_test = y_test[:num_test_images]\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "# Example usage:\n",
    "(X_train, y_train), (X_test, y_test) = get_data(5000, 1000)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "   # your code here\n",
    "# Assuming you have already loaded and preprocessed the data using the get_data function\n",
    "(X_train, _), (X_test, _) = get_data(num_train_images=5000, num_test_images=1000)\n",
    "\n",
    "# Print the value of X_train[1, 349]\n",
    "print(X_train[1, 349]) \n",
    "\n",
    "# Assuming you have already loaded and preprocessed the data using the get_data function\n",
    "(_, _), (X_test, y_test) = get_data(num_train_images=5000, num_test_images=1000)\n",
    "\n",
    "# Print the label in y_test[50]\n",
    "print(y_test[50])\n",
    "    #return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2rS86Dw5nQT",
    "outputId": "6e82889f-284b-4213-80a7-1552032c7277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(1000,)\n",
      "(5000, 784)\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data(5000,1000)\n",
    "## Print off the shape of these arrays to see what we are dealing with\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3j32G5d5nQd"
   },
   "source": [
    "** Expected Output **\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = get_data(5000,1000)\n",
    "## Print off the shape of these arrays to see what we are dealing with\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "(5000,)\n",
    "(1000,)\n",
    "(5000, 784)\n",
    "(1000, 784)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPSr43Tl5nQf"
   },
   "source": [
    "## Plotting the Data\n",
    "Let's see what this data looks like! Right now the images are \"flattened\" into a 1-D array of length 784. In order to plot the image we first need to reshape it to the correct size of 28x28. We'll print out the respective label to make sure we are plotting the right number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLi4Odvo5nQj",
    "outputId": "7d835666-70e3-42d1-d2e5-74f531f704ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 3 ## Change me to view different images\n",
    "\n",
    "print(\"Label: \", y_train[image_index])\n",
    "reshaped_image = X_train[image_index].reshape((28, 28))\n",
    "\n",
    "plt.imshow(reshaped_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9X1bnDB5nQv"
   },
   "source": [
    "## Question 2 - Training the Model\n",
    "Now that we have formatted our data, we can fit a model using sklearn's `RandomForestClassifier` class with 20 estimators and its random_state is set to 42. We'll write a function that will take as input the image and label variables that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `RandomForestClassifier` model which has a random state of 42 and number of estimators 20.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nqo-XA1f5nQz"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def train_model(X_train, y_train):\n",
    "   \n",
    "\n",
    "\n",
    "    # Create a RandomForestClassifier with 20 estimators and random state 42\n",
    "    model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have already loaded and preprocessed the data using the get_data function\n",
    "(X_train, y_train), _ = get_data(num_train_images=5000, num_test_images=1000)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "#random_forest_model = train_model(X_train, y_train)\n",
    "    #your code here\n",
    "   # return \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl5cToJm5nQ5",
    "outputId": "3034441e-47f9-46d0-f0bf-c0170aea93f5"
   },
   "outputs": [],
   "source": [
    "clf = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHN3AL3W5nRG"
   },
   "source": [
    "## Question 3 - Testing the model\n",
    "Now that you have trained your model, lets see how well it does on the test set. Write a function which returns the accuracy of your trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the accuracy of the model. This number should be between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMCnj6x85nRO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.891\n",
      "Precision for label 6: 0.9101123595505618\n",
      "F1-score for label 0: 0.9655172413793103\n"
     ]
    }
   ],
   "source": [
    "### START FUNCTION\n",
    "#def calculate_accuracy(clf, X_test, y_test):\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_accuracy(model, X_test, y_test):\n",
    "    # Flatten the images if needed\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = model.predict(X_test_flattened)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a trained model and X_test, y_test from the get_data function\n",
    "accuracy = calculate_accuracy(random_forest_model, X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_precision_for_label(model, X_test, y_test, label):\n",
    "    # Flatten the images if needed\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = model.predict(X_test_flattened)\n",
    "\n",
    "    # Calculate precision for the specified label\n",
    "    precision = precision_score(y_test, y_pred, labels=[label], average='micro')\n",
    "    \n",
    "    return precision\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a trained model and X_test, y_test from the get_data function\n",
    "precision_label_6 = calculate_precision_for_label(random_forest_model, X_test, y_test, label=6)\n",
    "print(\"Precision for label 6:\", precision_label_6)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_f1_score_for_label(model, X_test, y_test, label):\n",
    "    # Flatten the images if needed\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = model.predict(X_test_flattened)\n",
    "\n",
    "    # Calculate F1-score for the specified label\n",
    "    f1_score_label_0 = f1_score(y_test, y_pred, labels=[label], average='micro')\n",
    "    \n",
    "    return f1_score_label_0\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a trained model and X_test, y_test from the get_data function\n",
    "f1_score_label_0 = calculate_f1_score_for_label(random_forest_model, X_test, y_test, label=0)\n",
    "print(\"F1-score for label 0:\", f1_score_label_0)\n",
    "    #your code here\n",
    "    #return \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pqCRlXD5nRS",
    "outputId": "5f40a78b-8670-4a47-aa55-d4eea51b617a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891\n"
     ]
    }
   ],
   "source": [
    "print(calculate_accuracy(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsvYXM_h5nRi"
   },
   "source": [
    "Classification reports gives us more information on where our model is going wrong - looking specifically at the performance caused by Type I & II errors. Write a function which returns the classification report of your test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a classification report\n",
    "\n",
    "_**Hint**_ You don't need to do this manually, sklearn has a classification report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qv8ndyM05nRl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97        85\n",
      "           1       0.98      0.98      0.98       126\n",
      "           2       0.88      0.90      0.89       116\n",
      "           3       0.84      0.83      0.84       107\n",
      "           4       0.86      0.90      0.88       110\n",
      "           5       0.86      0.85      0.86        87\n",
      "           6       0.91      0.93      0.92        87\n",
      "           7       0.88      0.85      0.87        99\n",
      "           8       0.93      0.78      0.85        89\n",
      "           9       0.81      0.88      0.85        94\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### START FUNCTION\n",
    "#def get_class_report(clf, X_test, y_test):\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_classification_report(model, X_test, y_test):\n",
    "    # Flatten the images if needed\n",
    "    X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    # Predict labels for the test set\n",
    "    y_pred = model.predict(X_test_flattened)\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a trained model and X_test, y_test from the get_data function\n",
    "classification_report_result = generate_classification_report(random_forest_model, X_test, y_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_result)\n",
    "    #your code here\n",
    "   # return\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmtLlUT_5nRt",
    "outputId": "c4f52542-456b-4d61-c730-b1a040551469"
   },
   "outputs": [],
   "source": [
    "print(get_class_report(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ldfdObCV5nR3"
   },
   "source": [
    "## Plotting the results\n",
    "\n",
    "Lets actually see if your model has trained correctly. Lets plot some of the images with their predicted labels. Since we don't have the predictions stored in our notebooks memory, we need to call the predict function here first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tx9YOlcO5nR4",
    "outputId": "4fdfd235-6c9c-45b3-be29-7448fa88eeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for image at index 15: 5\n",
      "Predicted Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have a trained model (e.g., random_forest_model)\n",
    "# and X_test from the get_data function\n",
    "(_, _), (X_test, _) = get_data(num_train_images=5000, num_test_images=1000)\n",
    "\n",
    "# Flatten the image if needed\n",
    "X_test_flattened = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Get the predicted label for image at index 15\n",
    "predicted_label_index_15 = random_forest_model.predict(X_test_flattened[15:16])[0]\n",
    "\n",
    "print(\"Predicted label for image at index 15:\", predicted_label_index_15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "image_index = 1 ## Change me to see other predictions\n",
    "\n",
    "print(\"Predicted Label: \",preds[image_index])\n",
    "plt.imshow(X_test[image_index].reshape((28, 28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCirI2V05nR-"
   },
   "source": [
    "Nice work! Since we didn't use all the data in the beginning, there is a chance our performance can improve. Go change the amount of data we use to see how it affects the accuracy of your model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4_Image_Classification_model_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
